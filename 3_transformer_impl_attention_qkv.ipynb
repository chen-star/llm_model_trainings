{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chen-star/llm_model_trainings/blob/main/3_transformer_impl_attention_qkv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Attention(Q, K, V) = softmax(QT(K) /  ‚àödk  + M) V`"
      ],
      "metadata": {
        "id": "EQjKFX_Bz4tu"
      },
      "id": "EQjKFX_Bz4tu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Q = XW_Q\n",
        "K = XW_K\n",
        "V = XW_V\n",
        "```"
      ],
      "metadata": {
        "id": "xnbDh5cg03Im"
      },
      "id": "xnbDh5cg03Im"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úà Imports"
      ],
      "metadata": {
        "id": "1mqp7yBTwxa-"
      },
      "id": "1mqp7yBTwxa-"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import time"
      ],
      "metadata": {
        "id": "icjCjA3Hw5uE"
      },
      "id": "icjCjA3Hw5uE",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [0] üáπ Randomly generate data"
      ],
      "metadata": {
        "id": "tldrm7wlxHcr"
      },
      "id": "tldrm7wlxHcr"
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "vocabulary_size = 40\n",
        "batch_size = 4\n",
        "embedding_dimension = 13\n",
        "context_window_size = 8"
      ],
      "metadata": {
        "id": "C2qxE_mcw8PE"
      },
      "id": "C2qxE_mcw8PE",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly generated token_ids\n",
        "token_ids = torch.randint(low=0, high=vocabulary_size, size=(batch_size, context_window_size))\n",
        "print(f' token_ids.shape: {token_ids.shape}.\\n\\n token_ids: \\n {token_ids}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEe10KITxxQg",
        "outputId": "f1317474-b804-4cc9-afbb-1c6c2c018054"
      },
      "id": "AEe10KITxxQg",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " token_ids.shape: torch.Size([4, 8]).\n",
            "\n",
            " token_ids: \n",
            " tensor([[ 4,  0, 31,  9, 37, 29, 33,  7],\n",
            "        [30, 16, 18,  1, 38, 31,  7, 34],\n",
            "        [ 2,  6, 18, 37,  2, 11, 31, 15],\n",
            "        [30, 31, 29,  0, 26,  6, 14, 10]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a embedding layer\n",
        "embedding_layer = nn.Embedding(vocabulary_size, embedding_dimension)"
      ],
      "metadata": {
        "id": "V3nUuxkuyAsx"
      },
      "id": "V3nUuxkuyAsx",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# token_ids to embedding vectors\n",
        "X = embedding_layer(token_ids)\n",
        "print(f\"X.shape: {X.shape}\") # [batch_size, context_window_size, embedding_dimension]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIRYM_bRzMn2",
        "outputId": "a38d4df8-d0e2-4d29-9d54-21ee01370fb3"
      },
      "id": "HIRYM_bRzMn2",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape: torch.Size([4, 8, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [1] ‚úç Manual compute Attention(Q, K, V)"
      ],
      "metadata": {
        "id": "gql-ss_Ty0hV"
      },
      "id": "gql-ss_Ty0hV"
    },
    {
      "cell_type": "code",
      "source": [
        "# define W_Q, W_K, W_V\n",
        "q_layer = nn.Linear(embedding_dimension, embedding_dimension, bias=False)\n",
        "k_layer = nn.Linear(embedding_dimension, embedding_dimension, bias=False)\n",
        "v_layer = nn.Linear(embedding_dimension, embedding_dimension, bias=False)\n",
        "print(f\"q_layer.weight.shape: {q_layer.weight.shape}\")\n",
        "print(f\"k_layer.weight.shape: {k_layer.weight.shape}\")\n",
        "print(f\"v_layer.weight.shape: {v_layer.weight.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u3R_-TWyzAc",
        "outputId": "b62fc893-cb09-48fd-8969-0e7fc7191dbe"
      },
      "id": "4u3R_-TWyzAc",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "q_layer.weight.shape: torch.Size([13, 13])\n",
            "k_layer.weight.shape: torch.Size([13, 13])\n",
            "v_layer.weight.shape: torch.Size([13, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q = XW_Q\n",
        "# K = XW_K\n",
        "# V = XW_V\n",
        "Q = q_layer(X)\n",
        "K = k_layer(X)\n",
        "V = v_layer(X)\n",
        "print(f\"Q.shape: {Q.shape}\")\n",
        "print(f\"K.shape: {K.shape}\")\n",
        "print(f\"V.shape: {V.shape}\")"
      ],
      "metadata": {
        "id": "J43GTOon1Gew",
        "outputId": "5bf435a0-0e7c-43d0-b0f1-e24a5377f3be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "J43GTOon1Gew",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q.shape: torch.Size([4, 8, 13])\n",
            "K.shape: torch.Size([4, 8, 13])\n",
            "V.shape: torch.Size([4, 8, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actual implementation ...\n",
        "\n",
        "`Attention(Q, K, V) = softmax(QT(K) / ‚àödk + M) V`"
      ],
      "metadata": {
        "id": "WhNUzji42DZW"
      },
      "id": "WhNUzji42DZW"
    },
    {
      "cell_type": "code",
      "source": [
        "# QT(K)\n",
        "# Very similar to \"consine simlary between Q and K\"\n",
        "TK = K.transpose(-2, -1) # only transpose non-batch dimension\n",
        "QTK = Q @ TK\n",
        "\n",
        "# QT(K) / ‚àödk\n",
        "QTK_scaled = QTK / (embedding_dimension**0.5)\n",
        "\n",
        "# M\n",
        "M = torch.tril(torch.ones(batch_size, context_window_size, context_window_size))\n",
        "\n",
        "# QT(K) / ‚àödk + M\n",
        "QTK_scaled[M==0] = -torch.inf # ignore future values\n",
        "QTK_timed = QTK_scaled\n",
        "\n",
        "# softmax(QT(K) / ‚àödk + M)\n",
        "QTK_softmax = F.softmax(QTK_timed, dim=-1)\n",
        "\n",
        "# softmax(QT(K) / ‚àödk + M) V\n",
        "attention_score_matrix_manual = QTK_softmax @ V"
      ],
      "metadata": {
        "id": "zxTlTp0r1tL8"
      },
      "id": "zxTlTp0r1tL8",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"attention_score_matrix_manual.shape: {attention_score_matrix_manual.shape}\")"
      ],
      "metadata": {
        "id": "J840rDGs3WHU",
        "outputId": "527a4dc8-328d-41c7-80a9-4cd082f10b6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "J840rDGs3WHU",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_score_matrix_manual.shape: torch.Size([4, 8, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [2] üíª pytorch compute Attention(Q, K, V)"
      ],
      "metadata": {
        "id": "YTpUZ6ATpokZ"
      },
      "id": "YTpUZ6ATpokZ"
    },
    {
      "cell_type": "code",
      "source": [
        "attention_score_matrix_pytorch = F.scaled_dot_product_attention(Q, K, V,is_causal=True)"
      ],
      "metadata": {
        "id": "1BXvaSC2pdwA"
      },
      "id": "1BXvaSC2pdwA",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'attention_score_matrix_pytorch.shape: {attention_score_matrix_pytorch.shape}')"
      ],
      "metadata": {
        "id": "QKQf44bepxnb",
        "outputId": "ab85d64a-9d6a-4c57-d132-9ef08e8d4e6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QKQf44bepxnb",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_score_matrix_pytorch.shape: torch.Size([4, 8, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [3] ‚õ≥ Compare"
      ],
      "metadata": {
        "id": "Yl3aDo9tp45V"
      },
      "id": "Yl3aDo9tp45V"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Manual: \\n {attention_score_matrix_manual[0,:,]}\")\n",
        "print(f\"Pytorch: \\n {attention_score_matrix_pytorch[0,:,]}\")\n",
        "print(f\"Diff: \\n {attention_score_matrix_manual[0,:,] - attention_score_matrix_pytorch[0,:,]}\")"
      ],
      "metadata": {
        "id": "bb1SMLpmp2MX",
        "outputId": "bf54e725-cf2c-4143-ebc7-64d1df792109",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bb1SMLpmp2MX",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual: \n",
            " tensor([[-0.3066, -0.3039, -0.3997, -0.4372, -0.5935, -0.5126, -0.0176,  0.0851,\n",
            "          0.1074, -0.3081,  0.2435, -0.3186, -0.3887],\n",
            "        [-0.4857,  0.0479, -0.1943, -0.2638, -0.5883, -0.3097, -0.0661, -0.0534,\n",
            "         -0.2109, -0.0634,  0.3379, -0.1422,  0.0852],\n",
            "        [-0.3166,  0.0014, -0.4696,  0.0573, -0.3855, -0.5474,  0.2758, -0.1532,\n",
            "         -0.3485,  0.2125,  0.1137,  0.0491,  0.0582],\n",
            "        [-0.4392,  0.0222, -0.3426,  0.1745, -0.3594, -0.4893,  0.2037, -0.0517,\n",
            "         -0.3698, -0.0495,  0.3026,  0.1931,  0.2092],\n",
            "        [-0.3153,  0.3241, -0.1499,  0.4223, -0.2624, -0.0969,  0.1800, -0.1778,\n",
            "         -0.3410, -0.1705,  0.2683,  0.1369,  0.3790],\n",
            "        [-0.1241,  0.2801, -0.1456,  0.3337, -0.2018, -0.1631,  0.1281, -0.1919,\n",
            "         -0.3247,  0.0469,  0.0958,  0.1180,  0.2497],\n",
            "        [-0.2506,  0.2859, -0.2585,  0.4661, -0.1626, -0.0459,  0.2230, -0.1093,\n",
            "         -0.4111, -0.1289,  0.1709,  0.1349,  0.3194],\n",
            "        [-0.1553,  0.3317, -0.2657,  0.3990, -0.1489,  0.0032,  0.2442, -0.1542,\n",
            "         -0.4394, -0.0770,  0.1313,  0.1096,  0.2341]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Pytorch: \n",
            " tensor([[-0.3066, -0.3039, -0.3997, -0.4372, -0.5935, -0.5126, -0.0176,  0.0851,\n",
            "          0.1074, -0.3081,  0.2435, -0.3186, -0.3887],\n",
            "        [-0.4857,  0.0479, -0.1943, -0.2638, -0.5883, -0.3097, -0.0661, -0.0534,\n",
            "         -0.2109, -0.0634,  0.3379, -0.1422,  0.0852],\n",
            "        [-0.3166,  0.0014, -0.4696,  0.0573, -0.3855, -0.5474,  0.2758, -0.1532,\n",
            "         -0.3485,  0.2125,  0.1137,  0.0491,  0.0582],\n",
            "        [-0.4392,  0.0222, -0.3426,  0.1745, -0.3594, -0.4893,  0.2037, -0.0517,\n",
            "         -0.3698, -0.0495,  0.3026,  0.1931,  0.2092],\n",
            "        [-0.3153,  0.3241, -0.1499,  0.4223, -0.2624, -0.0969,  0.1800, -0.1778,\n",
            "         -0.3410, -0.1705,  0.2683,  0.1369,  0.3790],\n",
            "        [-0.1241,  0.2801, -0.1456,  0.3337, -0.2018, -0.1631,  0.1281, -0.1919,\n",
            "         -0.3247,  0.0469,  0.0958,  0.1180,  0.2497],\n",
            "        [-0.2506,  0.2859, -0.2585,  0.4661, -0.1626, -0.0459,  0.2230, -0.1093,\n",
            "         -0.4111, -0.1289,  0.1709,  0.1349,  0.3194],\n",
            "        [-0.1553,  0.3317, -0.2657,  0.3990, -0.1489,  0.0032,  0.2442, -0.1542,\n",
            "         -0.4394, -0.0770,  0.1313,  0.1096,  0.2341]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Diff: \n",
            " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-2.9802e-08,  1.3039e-08,  0.0000e+00, -1.4901e-08, -2.9802e-08,\n",
            "          0.0000e+00,  0.0000e+00, -1.4901e-08,  0.0000e+00,  1.4901e-08,\n",
            "          1.4901e-08,  7.4506e-09,  1.8626e-08],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4901e-08,  0.0000e+00,\n",
            "          0.0000e+00,  1.4901e-08, -7.4506e-09,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  1.4901e-08,  1.4901e-08],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-1.4901e-08,  0.0000e+00,  1.4901e-08,  0.0000e+00,  0.0000e+00,\n",
            "          1.4901e-08, -1.4901e-08, -1.4901e-08, -2.9802e-08, -1.1176e-08,\n",
            "         -7.4506e-09, -7.4506e-09,  1.4901e-08],\n",
            "        [ 0.0000e+00, -5.9605e-08, -5.9605e-08,  0.0000e+00, -2.9802e-08,\n",
            "         -4.4703e-08,  0.0000e+00,  7.4506e-09,  0.0000e+00,  2.9802e-08,\n",
            "          0.0000e+00,  0.0000e+00, -2.9802e-08],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}